{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15e8368-8bca-4e6e-a788-3b5d5a363da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d4f4d4-68ce-46a7-9188-9442bf05c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.readlines()\n",
    "\n",
    "# Load datasets\n",
    "train_file = \"path/to/train.txt\"\n",
    "val_file = \"path/to/emotion/val.txt\"\n",
    "test_file = \"path/to/test.txt\"\n",
    "train = load_data(train_file)\n",
    "val = load_data(val_file)\n",
    "test = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55aa1de-c9c4-4a15-b16b-35bfa9298f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into tweets and labels\n",
    "def get_tweet(data):\n",
    "    tweets = []\n",
    "    labels = []\n",
    "    for line in data:\n",
    "        tweet, label = line.strip().split(';')\n",
    "        tweets.append(tweet)\n",
    "        labels.append(label)\n",
    "    return tweets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dee8786-8fa0-413e-9253-04949d82dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tweets and labels\n",
    "tweets, labels = get_tweet(train)\n",
    "val_tweets, val_labels = get_tweet(val)\n",
    "test_tweets, test_labels = get_tweet(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e723bd40-dacc-436e-8382-c03dc6d37d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweets\n",
    "def get_sequences(tokenizer, tweets, maxlen=50):\n",
    "    sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    padded = pad_sequences(sequences, truncating='post', padding='post', maxlen=maxlen)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62bc5b4d-e676-4e65-b7ca-e1057e6d0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweets\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "padded_train_seq = get_sequences(tokenizer, tweets)\n",
    "padded_val_seq = get_sequences(tokenizer, val_tweets)\n",
    "padded_test_seq = get_sequences(tokenizer, test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf09c00-a1bd-4937-a3aa-e69bb698750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label index mappings\n",
    "classes = set(labels)\n",
    "class_to_index = {c: i for i, c in enumerate(classes)}\n",
    "index_to_class = {i: c for c, i in class_to_index.items()}\n",
    "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d735b3-8354-49d3-bc10-1965d3f03109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to indices\n",
    "train_labels = names_to_ids(labels)\n",
    "val_labels = names_to_ids(val_labels)\n",
    "test_labels = names_to_ids(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c145715-44fc-4529-b26f-d1b8cdcaabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(len(classes), activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ace0013-f8b0-4869-bc84-aa0f9d9f43f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.3673 - loss: 1.5477 - val_accuracy: 0.6850 - val_loss: 0.9055\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - accuracy: 0.7513 - loss: 0.6979 - val_accuracy: 0.7470 - val_loss: 0.6879\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.8590 - loss: 0.4187 - val_accuracy: 0.8300 - val_loss: 0.5177\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - accuracy: 0.9070 - loss: 0.2798 - val_accuracy: 0.8590 - val_loss: 0.4456\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - accuracy: 0.9419 - loss: 0.1876 - val_accuracy: 0.8765 - val_loss: 0.4242\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - accuracy: 0.9607 - loss: 0.1327 - val_accuracy: 0.8720 - val_loss: 0.4625\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9684 - loss: 0.1075 - val_accuracy: 0.8810 - val_loss: 0.4296\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - accuracy: 0.9735 - loss: 0.0912 - val_accuracy: 0.8655 - val_loss: 0.4768\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - accuracy: 0.9709 - loss: 0.0974 - val_accuracy: 0.8855 - val_loss: 0.4142\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9793 - loss: 0.0688 - val_accuracy: 0.8810 - val_loss: 0.4618\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.0539 - val_accuracy: 0.8745 - val_loss: 0.5137\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - accuracy: 0.9847 - loss: 0.0471 - val_accuracy: 0.8860 - val_loss: 0.4963\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - accuracy: 0.9862 - loss: 0.0433 - val_accuracy: 0.8795 - val_loss: 0.5399\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.9882 - loss: 0.0396 - val_accuracy: 0.8910 - val_loss: 0.4999\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - accuracy: 0.9900 - loss: 0.0351 - val_accuracy: 0.8900 - val_loss: 0.5558\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.9908 - loss: 0.0299 - val_accuracy: 0.8955 - val_loss: 0.4556\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.9922 - loss: 0.0258 - val_accuracy: 0.8710 - val_loss: 0.6429\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9864 - loss: 0.0387 - val_accuracy: 0.8820 - val_loss: 0.5413\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9906 - loss: 0.0304 - val_accuracy: 0.8890 - val_loss: 0.5298\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.9927 - loss: 0.0213 - val_accuracy: 0.8835 - val_loss: 0.6019\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "h = model.fit(padded_train_seq, train_labels, validation_data=(padded_val_seq, val_labels), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6d75b26-15c7-427e-b130-5ea9cc687e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict emotion from the command line\n",
    "def predict_emotion():\n",
    "    while True:\n",
    "        sentence = input(\"Enter a sentence (0 to quit): \")\n",
    "        if sentence == \"0\":\n",
    "            print(\"---------------------------------END--------------------------------------------\")\n",
    "            break\n",
    "        if sentence == \"\":\n",
    "            print(\"Enter the Sentence..!!\")\n",
    "            continue\n",
    "        seq = tokenizer.texts_to_sequences([sentence])\n",
    "        seq = pad_sequences(seq, maxlen=50, padding='post')\n",
    "        p = model.predict(seq)[0]\n",
    "        pred_class = index_to_class[np.argmax(p).astype('uint8')].capitalize()\n",
    "        print(f\"Predicted emotion: {pred_class}\")\n",
    "        print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "583c7cf2-ac6f-4ff9-994e-a70b07175331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence (0 to quit):  It was a wonderful day with NGO event.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted emotion: Joy\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence (0 to quit):  I feel very low today.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted emotion: Sadness\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence (0 to quit):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------END--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start the prediction loop\n",
    "predict_emotion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39093549-6520-4521-8636-5e0058eb39c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
